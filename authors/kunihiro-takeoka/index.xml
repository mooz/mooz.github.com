<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kunihiro Takeoka | Masafumi Oyamada</title>
    <link>https://mooz.github.io/authors/kunihiro-takeoka/</link>
      <atom:link href="https://mooz.github.io/authors/kunihiro-takeoka/index.xml" rel="self" type="application/rss+xml" />
    <description>Kunihiro Takeoka</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 01 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://mooz.github.io/images/icon_hud76b0b5cb03cbdbd01ad5fbc1aeef883_89416_512x512_fill_linear_center_2.png</url>
      <title>Kunihiro Takeoka</title>
      <link>https://mooz.github.io/authors/kunihiro-takeoka/</link>
    </image>
    
    <item>
      <title>Continuous Top-k Spatial-Keyword Search on Dynamic Objects</title>
      <link>https://mooz.github.io/publication/journals-vldb-yuyang-xcytoh-20/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://mooz.github.io/publication/journals-vldb-yuyang-xcytoh-20/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning from Unsure Responses</title>
      <link>https://mooz.github.io/publication/aaai2020-unsure-loss/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://mooz.github.io/publication/aaai2020-unsure-loss/</guid>
      <description>&lt;p&gt;Many annotation systems provide to add an unsure option in the labels, because
the annotators have different expertise, and they may not have enough confidence
to choose a label for some assigned instances. However, all the existing
approaches only learn the labels with a clear class name and ignore the unsure
responses. Due to the unsure response also account for a proportion of the
dataset (e.g., about 10-30% in real datasets), existing approaches lead to high
costs such as paying more money or taking more time to collect enough size of
labeled data. Therefore, it is a significant issue to make use of these unsure.&lt;/p&gt;
&lt;p&gt;In this paper, we make the unsure responses contribute to training classifiers.
We found a property that the instances corresponding to the unsure responses
always appear close to the decision boundary of classification. We design a loss
function called unsure loss based on this property. We extend the conventional
methods for classification and learning from crowds with this unsure loss.
Experimental results on realworld and synthetic data demonstrate the performance
of our method and its superiority over baseline methods.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Meimei: An Efficient Probabilistic Approach for Semantically Annotating Tables</title>
      <link>https://mooz.github.io/publication/aaai2019-meimei/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://mooz.github.io/publication/aaai2019-meimei/</guid>
      <description>&lt;p&gt;Given a large amount of table data, how can we find the tables that contain the
contents we want? A naive search fails when the column names are ambiguous, such
as if columns containing stock price information are named “Close” in one table
and named “P” in another table.&lt;/p&gt;
&lt;p&gt;One way of dealing with this problem that has been gaining attention is the
semantic annotation of table data columns by using canonical knowledge. While
previous studies successfully dealt with this problem for specific types of
table data such as web tables, it still remains for various other types of table
data: (1) most approaches do not handle table data with numerical values, and
(2) their predictive performance is not satisfactory.&lt;/p&gt;
&lt;p&gt;This paper presents a novel approach for table data annotation that combines a
latent probabilistic model with multilabel classifiers. It features three
advantages over previous approaches due to using highly predictive multi-label
classifiers in the probabilistic computation of semantic annotation. (1) It is
more versatile due to using multi-label classifiers in the probabilistic model,
which enables various types of data such as numerical values to be supported.
(2) It is more accurate due to the multi-label classifiers and probabilistic
model working together to improve predictive performance. (3) It is more
efficient due to potential functions based on multi-label classifiers reducing
the computational cost for annotation.&lt;/p&gt;
&lt;p&gt;Extensive experiments demonstrated the superiority of the proposed approach over
state-of-the-art approaches for semantic annotation of real data (183
human-annotated tables obtained from the UCI Machine Learning Repository).&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
