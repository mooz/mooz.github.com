[{"authors":["admin"],"categories":null,"content":"I am a senior principal researcher at NEC Corporation. I am now the director of Knowledge-Based Learning Research Group of Data Science Research Laboratories at NEC Corporation. I received my Ph.D. at University of Tsukuba in March 2018 under supervision of Prof. Hiroyuki Kitagawa.\nMy research interests are on helping data analysis using  data management technologies (DB) and  machine learning technologies (ML).\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://mooz.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a senior principal researcher at NEC Corporation. I am now the director of Knowledge-Based Learning Research Group of Data Science Research Laboratories at NEC Corporation. I received my Ph.D. at University of Tsukuba in March 2018 under supervision of Prof. Hiroyuki Kitagawa.\nMy research interests are on helping data analysis using  data management technologies (DB) and  machine learning technologies (ML).","tags":null,"title":"","type":"authors"},{"authors":["Yuyang Dong","Masafumi Oyamada"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648871703,"objectID":"35dcc09fb84f286378cbf6634ffa2a8f","permalink":"https://mooz.github.io/publication/dblp-conferencessigirym-22/","publishdate":"2022-04-02T03:55:03.4504Z","relpermalink":"/publication/dblp-conferencessigirym-22/","section":"publication","summary":"","tags":[],"title":"Table Enrichment System for Machine Learning (Demo)","type":"publication"},{"authors":["Kunihiro Takeoka","Kosuke Akimoto","Masafumi Oyamada"],"categories":[],"content":"","date":1630108800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630064481,"objectID":"de44d9269d95dd4331fd3a86b92e6fa9","permalink":"https://mooz.github.io/publication/emnlp2021-taxonomy-enrichment/","publishdate":"2021-08-27T11:41:21.478349Z","relpermalink":"/publication/emnlp2021-taxonomy-enrichment/","section":"publication","summary":"","tags":[],"title":"Low-resource Taxonomy Enrichment with Pretrained Language Models","type":"publication"},{"authors":["Kazunori Sakai","Yuyang Dong","Masafumi Oyamada","Kunihiro Takeoka","Takeshi Okadome"],"categories":[],"content":"","date":1629072000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630105193,"objectID":"3cfc7284539a7c155e1bb294f13a092b","permalink":"https://mooz.github.io/publication/sfdi2021-entity-matching-string-transformation/","publishdate":"2021-08-27T22:59:52.901247Z","relpermalink":"/publication/sfdi2021-entity-matching-string-transformation/","section":"publication","summary":"","tags":[],"title":"Entity Matching with String Transformation and Similarity-Based Features","type":"publication"},{"authors":["Genki Kusano","Masafumi Oyamada"],"categories":[],"content":"","date":1609632000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615851391,"objectID":"4ba1a92b6ad8563f57007a655f202dd6","permalink":"https://mooz.github.io/publication/icwsm2021-uil/","publishdate":"2021-03-15T23:36:31.723965Z","relpermalink":"/publication/icwsm2021-uil/","section":"publication","summary":"","tags":[],"title":"User Identity Linkage for Different Behavioral Patterns across Domains","type":"publication"},{"authors":["Yuyang Dong","Kunihiro Takeoka","Chuan Xiao","Masafumi Oyamada"],"categories":[],"content":"","date":1609545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614151549,"objectID":"17b69676814be5ea7a4411d8655f0885","permalink":"https://mooz.github.io/publication/icde2021-pexeso/","publishdate":"2021-02-24T07:25:49.765309Z","relpermalink":"/publication/icde2021-pexeso/","section":"publication","summary":"","tags":[],"title":"Efficient Joinable Table Discovery in Data Lake: A High-Dimensional Similarity-Based Approach","type":"publication"},{"authors":["Masafumi Enomoto","Kunihiro Takeoka","Yuyang Dong","Masafumi Oyamada","Takeshi Okadome"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614151555,"objectID":"bac51881322f077391c560a368708947","permalink":"https://mooz.github.io/publication/pakdd2021-prototype/","publishdate":"2021-02-24T07:25:55.680584Z","relpermalink":"/publication/pakdd2021-prototype/","section":"publication","summary":"","tags":[],"title":"Quality Control for Hierarchical Classification with Incomplete Annotations","type":"publication"},{"authors":["Yuyang Dong","Chuan Xiao","Hanxiong Chen","Jefferey Xu Yu","Kunihiro Takeoka","Masafumi Oyamada","Hiroyuki Kitagawa"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"b01835ddaf3e3b81868915e3a093b584","permalink":"https://mooz.github.io/publication/journals-vldb-yuyang-xcytoh-20/","publishdate":"2020-09-12T02:43:08.983105Z","relpermalink":"/publication/journals-vldb-yuyang-xcytoh-20/","section":"publication","summary":"","tags":null,"title":"Continuous Top-k Spatial-Keyword Search on Dynamic Objects","type":"publication"},{"authors":["Kunihiro Takeoka","Yuyang Dong","Masafumi Oyamada"],"categories":null,"content":"Many annotation systems provide to add an unsure option in the labels, because the annotators have different expertise, and they may not have enough confidence to choose a label for some assigned instances. However, all the existing approaches only learn the labels with a clear class name and ignore the unsure responses. Due to the unsure response also account for a proportion of the dataset (e.g., about 10-30% in real datasets), existing approaches lead to high costs such as paying more money or taking more time to collect enough size of labeled data. Therefore, it is a significant issue to make use of these unsure.\nIn this paper, we make the unsure responses contribute to training classifiers. We found a property that the instances corresponding to the unsure responses always appear close to the decision boundary of classification. We design a loss function called unsure loss based on this property. We extend the conventional methods for classification and learning from crowds with this unsure loss. Experimental results on realworld and synthetic data demonstrate the performance of our method and its superiority over baseline methods.\n","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"b886b9b1624e405efabb1f4f24fb0bde","permalink":"https://mooz.github.io/publication/aaai2020-unsure-loss/","publishdate":"2019-11-24T07:22:01.36361Z","relpermalink":"/publication/aaai2020-unsure-loss/","section":"publication","summary":"Many annotation systems provide to add an unsure option in the labels, because the annotators have different expertise, and they may not have enough confidence to choose a label for some assigned instances. However, all the existing approaches only learn the labels with a clear class name and ignore the unsure responses. Due to the unsure response also account for a proportion of the dataset (e.g., about 10-30% in real datasets), existing approaches lead to high costs such as paying more money or taking more time to collect enough size of labeled data.","tags":null,"title":"Learning from Unsure Responses","type":"publication"},{"authors":["Masafumi Oyamada"],"categories":null,"content":"Designing good features for machine learning models, which is called feature-engineering, is one of the most important tasks in data analysis. Well-designed features, which capture the characteristics of data, improve the predictive performance and explainability of the model. Since good features generally reflect the deep knowledge on business domains of the data and the analysis task, feature engineering is considered as one of the most difficult phases in data analysis.\nNowadays, AutoML is trying to automate the data science process by producing good features by autonomous algorithms such as feature-synthesis and feature-selection. While AutoML is making success in some extent, it cannot reproduce all the features crafted by expert data scientists in reality because of its huge search space.\nIn this paper, we take different approach for assisting feature engineering process: transfer expert data scientists knowledge as much as possible. Proposed approach extracts frequently used feature engineering operations from source codes or notebooks by pattern discovery. Since naive textual pattern discovery performs poor for the source code, our approach converts source codes into abstract syntax trees and discovers important feature engineering operations as subgraphs by performing frequent subgraph mining.\n","date":1576108800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576108800,"objectID":"2c8b7ed803580e940e44c0a504f07c74","permalink":"https://mooz.github.io/publication/bigdata2019-script-analysis/","publishdate":"2019-11-24T07:22:01.364477Z","relpermalink":"/publication/bigdata2019-script-analysis/","section":"publication","summary":"Designing good features for machine learning models, which is called feature-engineering, is one of the most important tasks in data analysis. Well-designed features, which capture the characteristics of data, improve the predictive performance and explainability of the model. Since good features generally reflect the deep knowledge on business domains of the data and the analysis task, feature engineering is considered as one of the most difficult phases in data analysis.","tags":null,"title":"Extracting Feature Engineering Knowledge from Data Science Notebooks","type":"publication"},{"authors":["Masafumi Oyamada"],"categories":["iOS","Emacs"],"content":"","date":1574581201,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574581201,"objectID":"a3fb9b9d7cdbf91b2713ceb8bac8c482","permalink":"https://mooz.github.io/project/ikeysnail/","publishdate":"2019-11-24T07:40:01Z","relpermalink":"/project/ikeysnail/","section":"project","summary":"Provides fully-configurable hardware keyboard functionalities for web browsing on iOS (iPadOS)","tags":["iOS","Emacs"],"title":"iKeySnail","type":"project"},{"authors":["Masafumi Oyamada"],"categories":["Linux","Emacs","Python"],"content":"","date":1574494805,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574494805,"objectID":"dbef5c6870fe0b251632b83561f407ba","permalink":"https://mooz.github.io/project/xkeysnail/","publishdate":"2019-11-23T07:40:05Z","relpermalink":"/project/xkeysnail/","section":"project","summary":"Yet another keyboard remapping tool for X environment","tags":["Linux","Emacs","Python"],"title":"xKeySnail","type":"project"},{"authors":["Masafumi Oyamada"],"categories":["Terminal","Emacs","Python"],"content":"","date":1574322018,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574322018,"objectID":"994d5e99a757feeb79f9333f9b5154b4","permalink":"https://mooz.github.io/project/percol/","publishdate":"2019-11-21T07:40:18Z","relpermalink":"/project/percol/","section":"project","summary":"An interactive grep tool in your terminal","tags":["Terminal","Emacs","Python"],"title":"percol","type":"project"},{"authors":["Masafumi Oyamada"],"categories":["Firefox","Emacs"],"content":"","date":1574235614,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574235614,"objectID":"1a011660bb1d83cc0326313b22c28b01","permalink":"https://mooz.github.io/project/keysnail/","publishdate":"2019-11-20T07:40:14Z","relpermalink":"/project/keysnail/","section":"project","summary":"Allows you to bind commands to key sequences in Mozilla Firefox","tags":["Firefox","Emacs"],"title":"KeySnail","type":"project"},{"authors":["Masafumi Oyamada"],"categories":["JavaScript"],"content":"","date":1574163883,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574163883,"objectID":"27c36f6387de0f7724c38cd11c45758d","permalink":"https://mooz.github.io/project/mispli/","publishdate":"2019-11-19T11:44:43Z","relpermalink":"/project/mispli/","section":"project","summary":"A Lisp implementation and REPL written in JavaScript, which supports static-scoping, lexical-closure, macro, and basic special forms","tags":["JavaScript"],"title":"MiSPLi","type":"project"},{"authors":["Masafumi Oyamada"],"categories":["Emacs","JavaScript"],"content":"","date":1574078283,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574078283,"objectID":"3ada2f4361e157652a37761bcde60e73","permalink":"https://mooz.github.io/project/org-js/","publishdate":"2019-11-18T11:58:03Z","relpermalink":"/project/org-js/","section":"project","summary":"A parser for org-mode notation written in JavaScript","tags":["Emacs","JavaScript"],"title":"org-js","type":"project"},{"authors":["Masafumi Oyamada"],"categories":["Emacs"],"content":"","date":1573991091,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573991091,"objectID":"23927d3a4d7ff287f3f9c0dcf0160d25","permalink":"https://mooz.github.io/project/zlc/","publishdate":"2019-11-17T11:44:51Z","relpermalink":"/project/zlc/","section":"project","summary":"Provides zsh like completion for minibuffer in Emacs","tags":["Emacs"],"title":"zlc.el","type":"project"},{"authors":["Masafumi Oyamada"],"categories":["JavaScript"],"content":"","date":1573904696,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573904696,"objectID":"4c7cd6b8e35d3bd8a45318c81c42fd31","permalink":"https://mooz.github.io/project/cc/","publishdate":"2019-11-16T11:44:56Z","relpermalink":"/project/cc/","section":"project","summary":"A chaos fractal generator written in JavaScript","tags":["JavaScript"],"title":"Chaotic Canvas","type":"project"},{"authors":["Masafumi Oyamada"],"categories":["Emacs"],"content":"","date":1573382186,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573382186,"objectID":"0062edc0a6fd5b74127541a735f2431d","permalink":"https://mooz.github.io/project/js-doc/","publishdate":"2019-11-10T10:36:26Z","relpermalink":"/project/js-doc/","section":"project","summary":"Add jsdoc-related functionalities for Emacs","tags":["Emacs"],"title":"js-doc.el","type":"project"},{"authors":["Masafumi Oyamada"],"categories":["Emacs"],"content":"","date":1573036477,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573036477,"objectID":"9c77f627d52db99f6a509beb499f1faf","permalink":"https://mooz.github.io/project/lemon-mode/","publishdate":"2019-11-06T10:34:37Z","relpermalink":"/project/lemon-mode/","section":"project","summary":"A major-mode for LEMON Parser Generator.","tags":["Emacs"],"title":"lemon-mode.el","type":"project"},{"authors":["Kunihiro Takeoka","Masafumi Oyamada","Shinji Nakadai","Takeshi Okadome"],"categories":null,"content":"Given a large amount of table data, how can we find the tables that contain the contents we want? A naive search fails when the column names are ambiguous, such as if columns containing stock price information are named “Close” in one table and named “P” in another table.\nOne way of dealing with this problem that has been gaining attention is the semantic annotation of table data columns by using canonical knowledge. While previous studies successfully dealt with this problem for specific types of table data such as web tables, it still remains for various other types of table data: (1) most approaches do not handle table data with numerical values, and (2) their predictive performance is not satisfactory.\nThis paper presents a novel approach for table data annotation that combines a latent probabilistic model with multilabel classifiers. It features three advantages over previous approaches due to using highly predictive multi-label classifiers in the probabilistic computation of semantic annotation. (1) It is more versatile due to using multi-label classifiers in the probabilistic model, which enables various types of data such as numerical values to be supported. (2) It is more accurate due to the multi-label classifiers and probabilistic model working together to improve predictive performance. (3) It is more efficient due to potential functions based on multi-label classifiers reducing the computational cost for annotation.\nExtensive experiments demonstrated the superiority of the proposed approach over state-of-the-art approaches for semantic annotation of real data (183 human-annotated tables obtained from the UCI Machine Learning Repository).\n","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"ca7a2f48169c09e0f8373747fd3faf0f","permalink":"https://mooz.github.io/publication/aaai2019-meimei/","publishdate":"2019-11-24T07:22:01.36361Z","relpermalink":"/publication/aaai2019-meimei/","section":"publication","summary":"Given a large amount of table data, how can we find the tables that contain the contents we want? A naive search fails when the column names are ambiguous, such as if columns containing stock price information are named “Close” in one table and named “P” in another table.\nOne way of dealing with this problem that has been gaining attention is the semantic annotation of table data columns by using canonical knowledge.","tags":null,"title":"Meimei: An Efficient Probabilistic Approach for Semantically Annotating Tables","type":"publication"},{"authors":["Masafumi Oyamada"],"categories":null,"content":"Range aggregation query is a fundamental operation in the feature engineering phase of the machine learning tasks, which computes statistics, such as the maximum and the standard deviation of a subset of records. Since the feature-engineering process is a trial-and-error process, data analysts repeatedly conduct tons of the range aggregation queries by changing the range conditions, which results in a heavy workload. To accelerate such repetitive range aggregation queries, we propose Adaptive Partial Aggregation Tree (APA-tree), which drastically reduces the amount of I/Os that happen in executing the range aggregation queries. The APA-tree partitions the data into several groups, executes range aggregations on each subgroups to obtain partial results, and caches the results in an imbalanced binary-tree. The APA-tree executes subsequent queries by reusing the cached partial query results as much as possible on the basis of the divide-and-conquer characteristic of the range aggregations. Experimental results confirm that APA-tree outperforms conventional partial aggregation methods regarding the amount of I/Os, especially in a skewed workload.\n","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"ccaddc35895608a52a0f4bfa74c67d0b","permalink":"https://mooz.github.io/publication/bigdata2018-apa-tree/","publishdate":"2019-11-24T07:22:01.364477Z","relpermalink":"/publication/bigdata2018-apa-tree/","section":"publication","summary":"Range aggregation query is a fundamental operation in the feature engineering phase of the machine learning tasks, which computes statistics, such as the maximum and the standard deviation of a subset of records. Since the feature-engineering process is a trial-and-error process, data analysts repeatedly conduct tons of the range aggregation queries by changing the range conditions, which results in a heavy workload. To accelerate such repetitive range aggregation queries, we propose Adaptive Partial Aggregation Tree (APA-tree), which drastically reduces the amount of I/Os that happen in executing the range aggregation queries.","tags":null,"title":"Accelerating Feature Engineering with Adaptive Partial Aggregation Tree","type":"publication"},{"authors":["Masafumi Oyamada","Jianquan Liu","Shinji Ito","Kazuyo Narita","Takuya Araki","Hiroyuki Kitagawa"],"categories":null,"content":"In this paper, we present CVS (Compressed Vector Set), a fast and space-efficient data mining framework that efficiently handles both sparse and dense datasets. CVS holds a set of vectors in a compressed format and conducts primitive vector operations, such as lp-norm and dot product, without decompression. By combining these primitive operations, CVS accelerates prominent data mining or machine learning algorithms including k-nearest neighbor algorithm, stochastic gradient descent algorithm on logistic regression, and kernel methods. In contrast to the commonly used sparse matrix/vector representation, which is not effective for dense datasets, CVS efficiently handles sparse datasets and dense datasets in a unified manner. Our experimental results demonstrate that CVS can process both dense datasets and sparse datasets faster than conventional sparse vector representation with smaller memory usage.\n","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"a2f4d87a8aa3a9c3f290b47aadc01c10","permalink":"https://mooz.github.io/publication/jip2018-compressed-machine-learning/","publishdate":"2019-11-24T07:22:01.364148Z","relpermalink":"/publication/jip2018-compressed-machine-learning/","section":"publication","summary":"In this paper, we present CVS (Compressed Vector Set), a fast and space-efficient data mining framework that efficiently handles both sparse and dense datasets. CVS holds a set of vectors in a compressed format and conducts primitive vector operations, such as lp-norm and dot product, without decompression. By combining these primitive operations, CVS accelerates prominent data mining or machine learning algorithms including k-nearest neighbor algorithm, stochastic gradient descent algorithm on logistic regression, and kernel methods.","tags":null,"title":"Compressed Vector Set: A Fast and Space-Efficient Data Mining Framework","type":"publication"},{"authors":["Masafumi Oyamada","Shinji Nakadai"],"categories":null,"content":"Given a collection of basic customer demographics (e.g., age and gender) and their behavioral data (e.g., item purchase histories), how can we predict sensitive demographics (e.g., income and occupation) that not every customer makes available? This demographics prediction problem is modeled as a classification task in which a customer\u0026rsquo;s sensitive demographic y is predicted from his feature vector x.\nSo far, two lines of work have tried to produce a \u0026ldquo;good\u0026rdquo; feature vector x from the customer\u0026rsquo;s behavioral data: (1) application-specific feature engineering using behavioral data and (2) representation learning (such as singular value decomposition or neuralembedding) on behavioral data. Although these approaches successfully improve the predictive performance, (1) designing a good feature requires domain experts to make a great effort and (2) features obtained from representation learning are hard to interpret.\nTo overcome these problems, we present a Relational Infinite Support Vector Machine (R-iSVM), a mixture-of-experts model that can leverage behavioral data. Instead of augmenting the feature vectors of customers, R-iSVM uses behavioral data to find out behaviorally similar customerclusters and constructs a local prediction model at each customer cluster. In doing so, R-iSVM successfully improves the predictive performance withoutrequiring application-specific feature designing and hard-to-interpret representations.\nExperimental results on three real-world datasets demonstrate the predictive performance and interpretability of R-iSVM. Furthermore, R-iSVM can co-exist with previous demographics prediction methods to further improve their predictive performance.\n","date":1509494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509494400,"objectID":"e6c3ad51aa86ba5601facbed656b3bf8","permalink":"https://mooz.github.io/publication/icdm2017-relational-mixture-of-experts/","publishdate":"2019-11-24T07:22:01.364782Z","relpermalink":"/publication/icdm2017-relational-mixture-of-experts/","section":"publication","summary":"Given a collection of basic customer demographics (e.g., age and gender) and their behavioral data (e.g., item purchase histories), how can we predict sensitive demographics (e.g., income and occupation) that not every customer makes available? This demographics prediction problem is modeled as a classification task in which a customer\u0026rsquo;s sensitive demographic y is predicted from his feature vector x.\nSo far, two lines of work have tried to produce a \u0026ldquo;good\u0026rdquo; feature vector x from the customer\u0026rsquo;s behavioral data: (1) application-specific feature engineering using behavioral data and (2) representation learning (such as singular value decomposition or neuralembedding) on behavioral data.","tags":null,"title":"Relational Mixture of Experts: Explainable Demographics Prediction with Behavioral Data","type":"publication"},{"authors":["Katsufumi Tomobe","Masafumi Oyamada","Shinji Nakadai"],"categories":null,"content":"This paper presents a new probabilistic generative model (PGM) that predicts links for isolated nodes in a heterogeneous network using textual data. In conventional PGMs, a link between two nodes is predicted on the basis of the nodes’ other existing links. This method makes it difficult to predict links for isolated nodes, which happens when new items are recommended. In this study, we first naturally expand the relational topic model (RTM) to a heterogeneous network (Hetero-RTM). However, this simple extension degrades performance in a link prediction for existing nodes. We present a new model called the Grouped Hetero-RTM that has both latent topics and latent clusterings. Through intensive experiments that simulate real recommendation problems, the Grouped Hetero-RTM outperforms baseline methods at predicting links for isolated nodes. This model, furthermore, performs as effectively as the stochastic block model in the link prediction for existing nodes. We also find that the Grouped Hetero-RTM is effective for various textual data such as item reviews and movie descriptions.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"346783faf48a181871c725e0574ae6a8","permalink":"https://mooz.github.io/publication/pakdd2017-topic-bi-clustering/","publishdate":"2019-11-24T07:22:01.365086Z","relpermalink":"/publication/pakdd2017-topic-bi-clustering/","section":"publication","summary":"This paper presents a new probabilistic generative model (PGM) that predicts links for isolated nodes in a heterogeneous network using textual data. In conventional PGMs, a link between two nodes is predicted on the basis of the nodes’ other existing links. This method makes it difficult to predict links for isolated nodes, which happens when new items are recommended. In this study, we first naturally expand the relational topic model (RTM) to a heterogeneous network (Hetero-RTM).","tags":null,"title":"Link Prediction for Isolated Nodes in Heterogeneous Network by Topic-Based Co-clustering","type":"publication"},{"authors":["Masafumi Oyamada","Jianquan Liu","Kazuyo Narita","Takuya Araki"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"631af6912867f822414aec976f5b629e","permalink":"https://mooz.github.io/publication/apweb2014-moarle/","publishdate":"2019-11-24T07:22:01.365418Z","relpermalink":"/publication/apweb2014-moarle/","section":"publication","summary":"","tags":null,"title":"MOARLE: Matrix Operation Accelerator Based on Run-Length Encoding","type":"publication"},{"authors":["Masafumi Oyamada","Hideyuki Kawashima","Hiroyuki Kitagawa"],"categories":null,"content":"","date":1370044800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1370044800,"objectID":"5015eddf80f7e88ab3185fa17af3d5f3","permalink":"https://mooz.github.io/publication/acr2013-transactional-stream/","publishdate":"2013-06-01T00:00:00Z","relpermalink":"/publication/acr2013-transactional-stream/","section":"publication","summary":"","tags":null,"title":"Data Stream Processing with Concurrency Control","type":"publication"},{"authors":["Masafumi Oyamada","Hideyuki Kawashima","Hiroyuki Kitagawa"],"categories":null,"content":"A recent trend in data stream processing shows the use of advanced continuous queries (CQs) that reference non-streaming resources such as relational data in databases and machine learning models. Since non-streaming resources could be shared among multiple systems, resources may be updated by the systems during the CQ execution. As a consequence, CQs may reference resources inconsistently, and lead to a wide range of problems from inappropriate results to fatal system failures. We address this inconsistency problem by introducing the concept of transaction processing onto data stream processing. We introduce CQ-derived transaction, a concept that derives read-only transactions from CQs, and illustrate that the inconsistency problem is solved by ensuring serializability of derived transactions and resource updating transactions. To ensure serializability, we propose three CQ-processing strategies based on concurrency control techniques: two-phase lock strategy, snapshot strategy, and optimistic strategy. Experimental study shows our CQ-processing strategies guarantee proper results, and their performances are comparable to the performance of conventional strategy that could produce improper results.\n","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"42fbb6745d39779a831731f21e8231d3","permalink":"https://mooz.github.io/publication/sac2013-transactional-stream/","publishdate":"2019-11-24T07:22:01.365725Z","relpermalink":"/publication/sac2013-transactional-stream/","section":"publication","summary":"A recent trend in data stream processing shows the use of advanced continuous queries (CQs) that reference non-streaming resources such as relational data in databases and machine learning models. Since non-streaming resources could be shared among multiple systems, resources may be updated by the systems during the CQ execution. As a consequence, CQs may reference resources inconsistently, and lead to a wide range of problems from inappropriate results to fatal system failures.","tags":null,"title":"Continuous Query Processing with Concurrency Control: Reading Updatable Resources Consistently","type":"publication"},{"authors":["Masafumi Oyamada","Hideyuki Kawashima","Hiroyuki Kitagawa"],"categories":null,"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293840000,"objectID":"de1f526ff720d33d63c077be1a96c1c4","permalink":"https://mooz.github.io/publication/3pgcic2011-sequential-transaction/","publishdate":"2019-11-24T07:22:01.366028Z","relpermalink":"/publication/3pgcic2011-sequential-transaction/","section":"publication","summary":"","tags":null,"title":"Efficient Invocation of Transaction Sequences Triggered by Data Streams","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d6c6c842e5cecb88919d8a0c41dc8dde","permalink":"https://mooz.github.io/authors/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/","section":"","summary":"","tags":null,"title":"","type":"page"}]