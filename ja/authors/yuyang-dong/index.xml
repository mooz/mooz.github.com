<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yuyang Dong | Masafumi Oyamada</title>
    <link>https://mooz.github.io/ja/authors/yuyang-dong/</link>
      <atom:link href="https://mooz.github.io/ja/authors/yuyang-dong/index.xml" rel="self" type="application/rss+xml" />
    <description>Yuyang Dong</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>ja</language><lastBuildDate>Sun, 01 Jan 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://mooz.github.io/images/icon_hud76b0b5cb03cbdbd01ad5fbc1aeef883_89416_512x512_fill_linear_center_2.png</url>
      <title>Yuyang Dong</title>
      <link>https://mooz.github.io/ja/authors/yuyang-dong/</link>
    </image>
    
    <item>
      <title>DeepJoin: Joinable Table Discovery with Pre-trained Language Models</title>
      <link>https://mooz.github.io/ja/publication/vldb23-deepjoin/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://mooz.github.io/ja/publication/vldb23-deepjoin/</guid>
      <description></description>
    </item>
    
    <item>
      <title>QA-Matcher: Unsupervised Entity Matching Using a Question Answering Model</title>
      <link>https://mooz.github.io/ja/publication/pakdd2023-qamatcher/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://mooz.github.io/ja/publication/pakdd2023-qamatcher/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Table Enrichment System for Machine Learning (Demo)</title>
      <link>https://mooz.github.io/ja/publication/dblp-conferencessigirym-22/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://mooz.github.io/ja/publication/dblp-conferencessigirym-22/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Entity Matching with String Transformation and Similarity-Based Features</title>
      <link>https://mooz.github.io/ja/publication/sfdi2021-entity-matching-string-transformation/</link>
      <pubDate>Mon, 16 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://mooz.github.io/ja/publication/sfdi2021-entity-matching-string-transformation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Efficient Joinable Table Discovery in Data Lake: A High-Dimensional Similarity-Based Approach</title>
      <link>https://mooz.github.io/ja/publication/icde2021-pexeso/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://mooz.github.io/ja/publication/icde2021-pexeso/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Quality Control for Hierarchical Classification with Incomplete Annotations</title>
      <link>https://mooz.github.io/ja/publication/pakdd2021-prototype/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://mooz.github.io/ja/publication/pakdd2021-prototype/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Continuous Top-k Spatial-Keyword Search on Dynamic Objects</title>
      <link>https://mooz.github.io/ja/publication/journals-vldb-yuyang-xcytoh-20/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://mooz.github.io/ja/publication/journals-vldb-yuyang-xcytoh-20/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning from Unsure Responses</title>
      <link>https://mooz.github.io/ja/publication/aaai2020-unsure-loss/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://mooz.github.io/ja/publication/aaai2020-unsure-loss/</guid>
      <description>&lt;p&gt;Many annotation systems provide to add an unsure option in the labels, because
the annotators have different expertise, and they may not have enough confidence
to choose a label for some assigned instances. However, all the existing
approaches only learn the labels with a clear class name and ignore the unsure
responses. Due to the unsure response also account for a proportion of the
dataset (e.g., about 10-30% in real datasets), existing approaches lead to high
costs such as paying more money or taking more time to collect enough size of
labeled data. Therefore, it is a significant issue to make use of these unsure.&lt;/p&gt;
&lt;p&gt;In this paper, we make the unsure responses contribute to training classifiers.
We found a property that the instances corresponding to the unsure responses
always appear close to the decision boundary of classification. We design a loss
function called unsure loss based on this property. We extend the conventional
methods for classification and learning from crowds with this unsure loss.
Experimental results on realworld and synthetic data demonstrate the performance
of our method and its superiority over baseline methods.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
